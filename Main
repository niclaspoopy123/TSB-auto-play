 -- =================================================================================
--// INSTRUCTION: This script must be placed in StarterPlayer > StarterPlayerScripts
--// to ensure it runs automatically and persists when your character changes.
-- =================================================================================
--// SELF-LEARNING COMBAT FRAMEWORK V33.0 - "PROJECT TITAN" (Upgraded by GitHub Copilot)
--// USER: niclaspoopy123
--// BUILD DATE: 2025-10-26
--// UPDATE: Implemented true Q-Learning for smarter, forward-looking decisions.
--// CHANGE: The AI is now more robust, with better targeting, error handling, and code structure.
-- =================================================================================
--[[
V33.0 PATCH NOTES (PROJECT TITAN):
- NEW (TRUE Q-LEARNING): The learning algorithm has been upgraded from a simple value update to a proper Q-Learning model. The AI now considers the potential future value of its next best move, leading to more sophisticated, long-term strategies.
- IMPROVED (SMARTER TARGETING): The target-scoring algorithm now penalizes targets moving at high velocity, making the AI prioritize engaging enemies it's more likely to hit.
- IMPROVED (ROBUSTNESS): Added comprehensive checks for target validity throughout the combat loop to prevent errors when a target is lost or destroyed unexpectedly.
- IMPROVED (EXPLOITSEEKER TACTIC): The 'ExploitSeeker' tactic now uses a weighted-random selection, promoting more varied and unpredictable exploratory actions to discover glitches.
- REFACTOR (MODULAR DESIGN): The entire script has been reorganized into logical modules (Services, Constants, AI, CoreLogic, etc.) for significantly improved readability and easier maintenance.

V32.2 PATCH NOTES (PROJECT ANOMALY):
- NEW (GLITCH COMBO SYSTEM): When the GlitchScanner detects an anomaly, it now triggers a 1.5-second "glitch combo" window.
- IMPROVED (GLITCH CAPITALIZATION): During the glitch combo window, the AI will ignore normal tactics and immediately attempt a high-priority ATTACK or SPECIAL move to weaponize the glitch.
--]]

--// ================= SERVICES ================= //
local Players = game:GetService("Players")
local RunService = game:GetService("RunService")
local Workspace = game:GetService("Workspace")
local LogService = game:GetService("LogService")

--// ================= LOCAL PLAYER ================= //
local player = Players.LocalPlayer

--// ================= AI'S PERSISTENT BRAIN ================= //
-- This table stores the AI's long-term memory, including learned values and statistics.
-- It persists across character resets, allowing the AI to learn over multiple sessions.
local AI = {
  State = {}, -- Volatile state, reset on character spawn.
  Score = 0, -- Persistent score.
  IdentifiedCharacter = "Unknown",
  AvailableMoves = {},
  ActionStats = { -- Persistent learning data.
      totalTrials = 0,
      Aggressive = { total = 0, ATTACK = { count = 0, value = 0 }, SPECIAL = { count = 0, value = 0 }, EVADE = { count = 0, value = 0 }, FEINT = { count = 0, value = 0 }, REPOSITION = { count = 0, value = 0 } },
      Defensive = { total = 0, ATTACK = { count = 0, value = 0 }, SPECIAL = { count = 0, value = 0 }, EVADE = { count = 0, value = 0 }, FEINT = { count = 0, value = 0 }, REPOSITION = { count = 0, value = 0 } },
      BaitAndPunish = { total = 0, ATTACK = { count = 0, value = 0 }, SPECIAL = { count = 0, value = 0 }, EVADE = { count = 0, value = 0 }, FEINT = { count = 0, value = 0 }, REPOSITION = { count = 0, value = 0 } },
      Finisher = { total = 0, ATTACK = { count = 0, value = 0 }, SPECIAL = { count = 0, value = 0 }, EVADE = { count = 0, value = 0 }, FEINT = { count = 0, value = 0 }, REPOSITION = { count = 0, value = 0 } },
      ExploitSeeker = { total = 0, ATTACK = { count = 0, value = 0 }, SPECIAL = { count = 0, value = 0 }, EVADE = { count = 0, value = 0 }, FEINT = { count = 0, value = 0 }, REPOSITION = { count = 0, value = 0 } },
  },
  --// ANOMALY: Module for actively reading the game for glitches.
  GlitchScanner = {
      isGlitchDetected = false,
      glitchType = "None",
      lastVelocityMagnitude = 0,
      lastHumanoidState = "None",
      detectionTime = 0,
  },
  Evaluation = {},
  Actions = {},
  Learning = {}
}

--// ================= CORE INITIALIZATION ================= //

-- This function runs when the player's character is added to the game.
-- It sets up the entire combat system, constants, and event connections.
local function initializeCombatSystem(character)
  --// --- CHARACTER VALIDATION ---
  if not character then return end
  local humanoid = character:WaitForChild("Humanoid")
  local rootPart = character:WaitForChild("HumanoidRootPart")
  local communicateEvent = character:WaitForChild("Communicate", 5)

  if not (humanoid and rootPart and communicateEvent) then
      warn("Project Titan: Character is missing required components (Humanoid, HumanoidRootPart, or Communicate event). AI will not function.")
      return
  end

  --// --- LOCAL STATE & CONNECTIONS ---
  local connections = {} -- Stores all event connections for easy cleanup.
  local targetDiedConnection

  --// --- CHARACTER & MOVE IDENTIFICATION ---
  local CHARACTER_DATA = {
      ["The Slugger"] = { Moves = {"Homerun", "Beatdown", "Grand Slam"}, AttackRange = 35, KiteRange = 45 },
      ["Garou"] = { Moves = {"Whirlwind Kick", "Machine Gun Blows", "Flowing Water"}, AttackRange = 30, KiteRange = 40 },
      ["Genos"] = { Moves = {"Ignition Burst", "Jet Dive", "Blitz Shot"}, AttackRange = 50, KiteRange = 60 },
      ["Atomic Samurai"] = { Moves = {"Quick Slice", "Atmos Cleave", "Pinpoint Cut"}, AttackRange = 40, KiteRange = 50 },
      ["Sonic"] = { Moves = {"Flash Strike", "Explosive Shuriken"}, AttackRange = 45, KiteRange = 55 },
      ["Flashy Flash"] = { Moves = {"Split Second Counter"}, AttackRange = 38, KiteRange = 48 },
      ["Default"] = { Moves = {
          "Homerun", "Beatdown", "Grand Slam", "Flash Strike", "Whirlwind Kick",
          "Scatter", "Explosive Shuriken", "Machine Gun Blows", "Ignition Burst",
          "Blitz Shot", "Jet Dive", "Quick Slice", "Atmos Cleave", "Pinpoint Cut",
          "Split Second Counter", "Flowing Water", "Crushing Pull", "Windstorm Fury",
          "Stone Coffin", "Expulsive Push"
          }, AttackRange = 30, KiteRange = 40 }
  }

  local function IdentifyCharacter()
      local ownedMovesSet = {}
      local ownedMovesList = {}

      local function getTools(container)
          if not container then return end
          for _, tool in ipairs(container:GetChildren()) do
              if tool:IsA("Tool") and not ownedMovesSet[tool.Name] then
                  ownedMovesSet[tool.Name] = true
                  table.insert(ownedMovesList, tool.Name)
              end
          end
      end

      getTools(player:WaitForChild("Backpack"))
      getTools(character)

      for characterName, data in pairs(CHARACTER_DATA) do
          if characterName ~= "Default" then
              local moveMatch = false
              for _, moveName in ipairs(data.Moves) do
                  if ownedMovesSet[moveName] then
                      moveMatch = true
                      break
                  end
              end
              if moveMatch then
                  AI.IdentifiedCharacter, AI.AvailableMoves = characterName, ownedMovesList
                  print("Character identified as:", characterName)
                  return CHARACTER_DATA[characterName]
              end
          end
      end

      AI.IdentifiedCharacter, AI.AvailableMoves = "Custom", ownedMovesList
      print("Custom character detected. Using owned moves:", table.concat(ownedMovesList, ", "))
      return CHARACTER_DATA.Default
  end

  local characterInfo = IdentifyCharacter()

  --// --- CONSTANTS ---
  -- Centralized constants for easy tuning of the AI's behavior.
  local CONST = {
      AGGRO_RANGE = 200, ATTACK_RANGE = characterInfo.AttackRange or 30, KITE_RANGE = characterInfo.KiteRange or 40,
      PLANNING_COOLDOWN = 0, TARGET_SCAN_INTERVAL = 0.5,
      MAX_ENERGY = 500, ENERGY_REGEN_RATE = 100,
      COSTS = { SPECIAL = 10, DASH = 2, FEINT = 1, ATTACK = 0, REPOSITION = 0 },
      ATTACK_COOLDOWN = 0.05, SPECIAL_MOVE_COOLDOWN = 0.5, DASH_COOLDOWN = 0.1, FEINT_COOLDOWN = 1.0,
      FEINT_DURATION = 0.2, FEINT_SUCCESS_DISTANCE = 5,
      PERFECT_DODGE_WINDOW = 0.5, PUNISH_WINDOW_DURATION = 2.0, COMBO_WINDOW_DURATION = 2.0,
      BASE_PREDICTION_TIME = 0.05,
      INITIAL_UCB_EXPLORATION_FACTOR = 2.0, UCB_DECAY_RATE = 0.005,
      LEARNING_RATE_ALPHA = 0.3, DISCOUNT_FACTOR_GAMMA = 0.9, -- Key Q-Learning parameters
      COST_PENALTY_FACTOR = 0.1,
      REWARD_DAMAGE_DEALT_MULTIPLIER = 2.0, REWARD_PERFECT_DODGE = 25, REWARD_FEINT_SUCCESS = 10,
      PENALTY_DAMAGE_TAKEN_MULTIPLIER = -2.5, PENALTY_FAILED_ACTION = -5,
      TACTIC_CONFIDENCE_THRESHOLD = 50, TACTIC_CHANGE_COOLDOWN = 2.0,
      WEIGHTED_RANDOM_CHANCE = 0.15,
      EXPLOIT_SEEKER_CONFIDENCE_THRESHOLD = 20,
      EXPLOIT_SEEKER_COOLDOWN = 15.0,
      REWARD_ANOMALOUS_DAMAGE = 50,
      GLITCH_VELOCITY_THRESHOLD = 350,
      GLITCH_DETECTION_REWARD = 15,
      GLITCH_COMBO_WINDOW_DURATION = 1.5,
  }

  --// --- STATE MANAGEMENT ---
  function AI.ResetState(maxEnergy)
      AI.State = {
          currentTarget = nil, targetHumanoid = nil, targetTorso = nil,
          combatState = "IDLE", currentTactic = "BaitAndPunish",
          lastPlanTime = 0, lastActionTimes = { ATTACK = 0, SPECIAL = 0, EVADE = 0, FEINT = 0 },
          strafeDirection = 1, lastStrafeChange = 0, lastAction = "IDLE",
          lastTargetScanTime = 0, currentEnergy = maxEnergy,
          lastTargetHealth = 0, myHealth = humanoid.Health,
          isFeinting = false, feintStartTime = 0, distanceAtFeintStart = 0,
          isPerfectDodging = false, dodgeStartTime = 0,
          punishWindowEndTime = 0, comboStateEndTime = 0,
          glitchComboWindowEndTime = 0,
          tacticConfidence = 100, lastTacticChangeTime = 0,
          isTargetAttacking = false,
          lastExploitSeekerTriggerTime = 0,
      }
      print("AI State reset. Learned statistics and score have been preserved.")
  end
  AI.ResetState(CONST.MAX_ENERGY)
  AI.GlitchScanner.lastHumanoidState = humanoid:GetState()

  print(`Initializing Project Titan (V33.0) for {player.Name}... Character: {AI.IdentifiedCharacter}. GlitchScanner is active.`)

  --// ================= CORE AI LOGIC ================= //

  --// --- LEARNING MODULE ---
  function AI.Learning.Reinforce(tactic, action, rawReward, nextMaxQValue)
      local tacticStats = AI.ActionStats[tactic]
      if not tacticStats or not tacticStats[action] then return end

      local stats = tacticStats[action]
      local actionCost = CONST.COSTS[action] or 0
      local netReward = rawReward - (actionCost * CONST.COST_PENALTY_FACTOR)

      -- True Q-Learning Update (Bellman Equation):
      -- Q(s,a) = Q(s,a) + alpha * (reward + gamma * max_a' Q(s',a') - Q(s,a))
      -- Here, nextMaxQValue is an estimate of max_a' Q(s',a')
      local old_value = stats.value
      stats.value = old_value + CONST.LEARNING_RATE_ALPHA * (netReward + CONST.DISCOUNT_FACTOR_GAMMA * nextMaxQValue - old_value)

      stats.count += 1
      tacticStats.total += 1
      AI.ActionStats.totalTrials += 1

      -- Adjust tactic confidence based on performance.
      if rawReward > 0 then
          AI.State.tacticConfidence = math.min(150, AI.State.tacticConfidence + rawReward * 0.5)
      else
          AI.State.tacticConfidence = math.max(0, AI.State.tacticConfidence + rawReward)
      end
  end

  function AI.Learning.GetBestNextQValue(tactic, possibleActions)
      local tacticStats = AI.ActionStats[tactic]
      if not tacticStats then return 0 end

      local maxQ = -math.huge
      local foundAction = false
      for action, available in pairs(possibleActions) do
          if available and tacticStats[action] and tacticStats[action].count > 0 then
              local qValue = tacticStats[action].value / tacticStats[action].count -- Use average reward as Q-value approximation
              if qValue > maxQ then
                  maxQ = qValue
                  foundAction = true
              end
          end
      end
      return foundAction and maxQ or 0
  end

  --// --- EVALUATION MODULE ---
  function AI.Evaluation.ChooseTactic(state)
      local now = os.clock()

      -- Highest priority: Glitch exploitation.
      if AI.GlitchScanner.isGlitchDetected and now - AI.GlitchScanner.detectionTime < 5.0 then
          if AI.State.currentTactic ~= "ExploitSeeker" then
              print(`GLITCH DETECTED (${AI.GlitchScanner.glitchType})! Forcing EXPLOITSEEKER tactic.`)
              -- Reinforce the action that *caused* the glitch.
              AI.Learning.Reinforce("ExploitSeeker", AI.State.lastAction, CONST.GLITCH_DETECTION_REWARD, 0) -- No future Q-value needed here.
          end
          return "ExploitSeeker"
      end

      -- Cooldown to prevent rapid tactic switching.
      if now - AI.State.lastTacticChangeTime < CONST.TACTIC_CHANGE_COOLDOWN then
          return AI.State.currentTactic
      end

      -- If confidence is critical, switch to experimental mode.
      if AI.State.tacticConfidence < CONST.EXPLOIT_SEEKER_CONFIDENCE_THRESHOLD and now - AI.State.lastExploitSeekerTriggerTime > CONST.EXPLOIT_SEEKER_COOLDOWN then
          AI.State.lastTacticChangeTime = now
          AI.State.lastExploitSeekerTriggerTime = now
          print("Confidence critical. Switching to EXPLOITSEEKER to find new strategies.")
          return "ExploitSeeker"
      end

      -- If confidence is high, stick with the current tactic for a bit longer.
      if AI.State.tacticConfidence > CONST.TACTIC_CONFIDENCE_THRESHOLD and os.clock() - AI.State.lastTacticChangeTime < CONST.TACTIC_CHANGE_COOLDOWN * 2 then
          return AI.State.currentTactic
      end

      -- Rule-based tactic selection.
      local newTactic
      if state.targetHealthPercent < 0.2 and state.distance < CONST.ATTACK_RANGE * 1.5 then newTactic = "Finisher"
      elseif state.myHealthPercent > 0.75 and state.energy > (CONST.MAX_ENERGY * 0.6) then newTactic = "Aggressive"
      elseif state.myHealthPercent < 0.35 or state.energy < (CONST.MAX_ENERGY * 0.25) then newTactic = "Defensive"
      else newTactic = "BaitAndPunish" end

      if newTactic ~= AI.State.currentTactic then
          AI.State.lastTacticChangeTime = now
          AI.State.tacticConfidence = 100 -- Reset confidence on switch.
          print("Tactic changed to:", newTactic)
      end
      return newTactic
  end

  function AI.Evaluation.FindBestActionByScore(state, tactic)
      local now = os.clock()

      -- Immediate capitalization windows (glitch or punish).
      local function isCapitalizeWindow()
          return now < AI.State.glitchComboWindowEndTime or now < AI.State.punishWindowEndTime
      end

      if isCapitalizeWindow() and state.inRange then
          if AI.State.glitchComboWindowEndTime > now then print("Executing Glitch Combo!") end
          if #AI.AvailableMoves > 0 and now - AI.State.lastActionTimes.SPECIAL > CONST.SPECIAL_MOVE_COOLDOWN and state.energy >= CONST.COSTS.SPECIAL then return "SPECIAL" end
          if now - AI.State.lastActionTimes.ATTACK > CONST.ATTACK_COOLDOWN then return "ATTACK" end
      end

      local function getPossibleActions()
          local actions = {}
          actions.ATTACK = (now - AI.State.lastActionTimes.ATTACK > ((now < AI.State.comboStateEndTime) and CONST.ATTACK_COOLDOWN * 0.5 or CONST.ATTACK_COOLDOWN)) and state.inRange
          actions.SPECIAL = (now - AI.State.lastActionTimes.SPECIAL > CONST.SPECIAL_MOVE_COOLDOWN) and (state.energy >= CONST.COSTS.SPECIAL) and state.inRange and (#AI.AvailableMoves > 0)
          actions.EVADE = (now - AI.State.lastActionTimes.EVADE > CONST.DASH_COOLDOWN) and (state.energy >= CONST.COSTS.DASH)
          actions.FEINT = (now - AI.State.lastActionTimes.FEINT > CONST.FEINT_COOLDOWN) and (state.energy >= CONST.COSTS.FEINT) and state.inRange
          actions.REPOSITION = true
          return actions
      end

      local possibleActions = getPossibleActions()

      if tactic == "ExploitSeeker" then
          local actionPool = {}
          for action, available in pairs(possibleActions) do
              if available and (action == "ATTACK" or action == "SPECIAL" or action == "EVADE" or action == "FEINT") then
                  table.insert(actionPool, action)
              end
          end
          return #actionPool > 0 and actionPool[math.random(#actionPool)] or "REPOSITION"
      end

      local tacticStats = AI.ActionStats[tactic]
      local actionScores = {}
      local currentExplorationFactor = CONST.INITIAL_UCB_EXPLORATION_FACTOR * math.exp(-CONST.UCB_DECAY_RATE * tacticStats.total)

      for action, available in pairs(possibleActions) do
          if available then
              local stats = tacticStats[action]
              local score
              if stats.count == 0 then
                  score = math.huge -- Prioritize untried actions.
              else
                  local averageReward = stats.value / stats.count -- Exploitation term
                  local explorationBonus = currentExplorationFactor * math.sqrt(math.log(tacticStats.total + 1) / stats.count) -- Exploration term
                  score = averageReward + explorationBonus
              end

              -- Apply situational modifiers.
              local modifier = 1.0
              if action == "EVADE" and state.isTargetAttacking then modifier = 1.5 end
              if (tactic == "BaitAndPunish" or tactic == "Defensive") and action == "EVADE" then modifier *= 1.2 end

              table.insert(actionScores, { action = action, score = score * modifier })
          end
      end

      if #actionScores == 0 then return "REPOSITION" end

      table.sort(actionScores, function(a, b) return a.score > b.score end)

      -- Occasionally take the second-best action to ensure exploration.
      if #actionScores > 1 and math.random() < CONST.WEIGHTED_RANDOM_CHANCE then
          return actionScores[2].action
      end

      return actionScores[1].action
  end

  --// --- ACTION MODULE ---
  function AI.Actions.Execute(action)
      local now = os.clock()
      AI.State.lastAction, AI.State.lastPlanTime = action, now

      if not AI.State.targetTorso then return end -- Safety check
      local targetPos = AI.State.targetTorso.Position

      local cost = CONST.COSTS[action:upper()] or 0
      AI.State.currentEnergy -= cost

      if action == "FEINT" then
          communicateEvent:FireServer({["Goal"]="Feint"})
          AI.State.lastActionTimes.FEINT = now
          AI.State.isFeinting, AI.State.feintStartTime, AI.State.distanceAtFeintStart = true, now, (rootPart.Position - targetPos).Magnitude
      elseif action == "ATTACK" then
          communicateEvent:FireServer({["Mobile"]=true, ["Goal"]="LeftClick"})
          AI.State.lastActionTimes.ATTACK = now
          AI.State.punishWindowEndTime = 0
      elseif action == "SPECIAL" then
          if #AI.AvailableMoves > 0 then
              local moveName = AI.AvailableMoves[math.random(#AI.AvailableMoves)]
              local tool = player.Backpack:FindFirstChild(moveName) or character:FindFirstChild(moveName)
              if tool then
                  communicateEvent:FireServer({["Tool"] = tool, ["Goal"] = "Console Move"})
                  AI.State.lastActionTimes.SPECIAL = now
                  AI.State.punishWindowEndTime = 0
              end
          end
      elseif action == "EVADE" then
          local dashDir = rootPart.CFrame.RightVector * (math.random() > 0.5 and 1 or -1)
          communicateEvent:FireServer({["Dash"]=dashDir.Unit, ["Key"]="Q", ["Goal"]="KeyPress"})
          AI.State.lastActionTimes.EVADE = now
          AI.State.isPerfectDodging, AI.State.dodgeStartTime = true, now
      elseif action == "REPOSITION" then
          if now - AI.State.lastStrafeChange > (1.0 + math.random()) then
              AI.State.strafeDirection *= -1
              AI.State.lastStrafeChange = now
          end

          local currentDist = (rootPart.Position - targetPos).Magnitude
          local desiredRange
          if AI.State.currentTactic == "Defensive" then desiredRange = CONST.KITE_RANGE
          elseif AI.State.currentTactic == "Finisher" or AI.State.currentTactic == "Aggressive" then desiredRange = CONST.ATTACK_RANGE * 0.7
          else desiredRange = CONST.ATTACK_RANGE * 0.9 end

          local moveDirection = (targetPos - ((targetPos - rootPart.Position).Unit * desiredRange) + (rootPart.CFrame.RightVector * 10 * AI.State.strafeDirection))
          humanoid:MoveTo(moveDirection)

          -- Reinforce based on how well the AI maintains desired distance.
          local distanceError = math.abs(currentDist - desiredRange)
          local reward = math.max(0, 1 - (distanceError / desiredRange)) * 2
          AI.Learning.Reinforce(AI.State.currentTactic, "REPOSITION", reward, 0)
      end
  end

  --// ================= HELPER & UPDATE FUNCTIONS ================= //

  local function Cleanup()
      if targetDiedConnection then targetDiedConnection:Disconnect(); targetDiedConnection = nil end
      for _, c in ipairs(connections) do c:Disconnect() end
      connections = {}
      AI.State.combatState = "IDLE"
      AI.State.currentTarget = nil
      print("Project Titan has been shut down for this character.")
  end

  local function GetTargetScore(targetCharacter)
      if not targetCharacter or not targetCharacter.Parent or not targetCharacter:FindFirstChild("HumanoidRootPart") then return 0 end
      local targetHumanoid = targetCharacter:FindFirstChildOfClass("Humanoid")
      if not targetHumanoid or targetHumanoid.Health <= 0 then return 0 end

      local root = targetCharacter.HumanoidRootPart
      local distance = (rootPart.Position - root.Position).Magnitude
      if distance > CONST.AGGRO_RANGE then return 0 end

      local healthScore = (1 - (targetHumanoid.Health / targetHumanoid.MaxHealth)) * 1.5 -- Prioritize weaker targets.
      local distanceScore = (1 - (distance / CONST.AGGRO_RANGE)) -- Prioritize closer targets.
      local velocityScore = (root.AssemblyLinearVelocity.Magnitude > 25) and -0.75 or 0 -- Penalize fast-moving targets.

      return healthScore + distanceScore + velocityScore
  end

  local function EvaluateAndSetTarget()
      local bestTarget, highestScore = nil, -math.huge
      for _, p in ipairs(Players:GetPlayers()) do
          if p ~= player and p.Character then
              local score = GetTargetScore(p.Character)
              if score > highestScore then
                  highestScore, bestTarget = score, p.Character
              end
          end
      end

      if bestTarget and bestTarget ~= AI.State.currentTarget then
          if targetDiedConnection then targetDiedConnection:Disconnect() end

          local targetHumanoid = bestTarget:FindFirstChildOfClass("Humanoid")
          AI.State.currentTarget, AI.State.targetHumanoid, AI.State.targetTorso = bestTarget, targetHumanoid, bestTarget:FindFirstChild("Torso") or bestTarget:FindFirstChild("HumanoidRootPart")
          AI.State.lastTargetHealth = targetHumanoid and targetHumanoid.Health or 0

          targetDiedConnection = targetHumanoid.Died:Connect(function()
              AI.Score += 10
              print(`Target eliminated. New Score: {AI.Score}`)
              AI.State.currentTarget = nil
          end)
      end

      if not AI.State.currentTarget or not AI.State.targetHumanoid or AI.State.targetHumanoid.Health <= 0 then
          AI.State.combatState = "IDLE"
          AI.State.currentTarget = nil
      else
          AI.State.combatState = "ENGAGING"
      end
  end

  local function RunGlitchScanner()
      local now = os.clock()
      if AI.GlitchScanner.isGlitchDetected then
          if now - AI.GlitchScanner.detectionTime > 2.0 then
              AI.GlitchScanner.isGlitchDetected = false -- Reset after a few seconds.
          end
          return -- Don't stack detections.
      end

      local function triggerGlitch(glitchType)
          AI.GlitchScanner.isGlitchDetected = true
          AI.GlitchScanner.glitchType = glitchType
          AI.GlitchScanner.detectionTime = now
          AI.State.glitchComboWindowEndTime = now + CONST.GLITCH_COMBO_WINDOW_DURATION -- Start the combo window!
      end

      -- 1. Check for velocity spikes (flings).
      local currentVelocityMag = rootPart.AssemblyLinearVelocity.Magnitude
      if currentVelocityMag > CONST.GLITCH_VELOCITY_THRESHOLD and AI.GlitchScanner.lastVelocityMagnitude < CONST.GLITCH_VELOCITY_THRESHOLD then
          triggerGlitch("Velocity Spike")
      end
      AI.GlitchScanner.lastVelocityMagnitude = currentVelocityMag
      if AI.GlitchScanner.isGlitchDetected then return end

      -- 2. Check for unusual humanoid states.
      local currentState = humanoid:GetState()
      if currentState ~= AI.GlitchScanner.lastHumanoidState and (currentState == Enum.HumanoidStateType.StrafingNoPhysics or currentState == Enum.HumanoidStateType.None) then
          triggerGlitch("Humanoid State Anomaly")
      end
      AI.GlitchScanner.lastHumanoidState = currentState
      if AI.GlitchScanner.isGlitchDetected then return end

      -- 3. Check for NaN or extreme positions.
      local pos = rootPart.Position
      if not (pos.X == pos.X and pos.Y == pos.Y and pos.Z == pos.Z) then
          triggerGlitch("NaN Position")
      end
  end

  local function UpdateAIState(deltaTime)
      local now = os.clock()
      AI.State.currentEnergy = math.min(CONST.MAX_ENERGY, AI.State.currentEnergy + CONST.ENERGY_REGEN_RATE * deltaTime)

      if now - AI.State.lastTargetScanTime > CONST.TARGET_SCAN_INTERVAL then
          EvaluateAndSetTarget()
          AI.State.lastTargetScanTime = now
      end

      if AI.State.currentTarget and AI.State.currentTarget.Parent then
          local activeTool = AI.State.currentTarget:FindFirstChildOfClass("Tool")
          AI.State.isTargetAttacking = activeTool and activeTool.Enabled
      else
          AI.State.isTargetAttacking = false
      end

      RunGlitchScanner() -- Run the scanner every state update.
  end

  local function UpdateLearningAndRewards(now)
      if not AI.State.currentTarget or not AI.State.targetHumanoid or not AI.State.targetTorso then return end

      local tactic = AI.State.currentTactic

      -- Evaluate feint success/failure.
      if AI.State.isFeinting and now > AI.State.feintStartTime + CONST.FEINT_DURATION then
          AI.State.isFeinting = false
          local feintSucceeded = (rootPart.Position - AI.State.targetTorso.Position).Magnitude > AI.State.distanceAtFeintStart + CONST.FEINT_SUCCESS_DISTANCE
          local reward = feintSucceeded and CONST.REWARD_FEINT_SUCCESS or CONST.PENALTY_FAILED_ACTION
          AI.Learning.Reinforce(tactic, "FEINT", reward, 0)
          if feintSucceeded then
              AI.State.punishWindowEndTime = now + CONST.PUNISH_WINDOW_DURATION
          end
      end

      if AI.State.isPerfectDodging and now > AI.State.dodgeStartTime + CONST.PERFECT_DODGE_WINDOW then
          AI.State.isPerfectDodging = false
      end

      -- Evaluate damage dealt.
      local currentTargetHealth = AI.State.targetHumanoid.Health
      local damageDealt = AI.State.lastTargetHealth - currentTargetHealth
      if damageDealt > 0 then
          local action = AI.State.lastAction
          local reward
          if action ~= "ATTACK" and action ~= "SPECIAL" then
              print(`ANOMALY DETECTED: Damage dealt via ${action}. Rewarding heavily.`)
              reward = CONST.REWARD_ANOMALOUS_DAMAGE
          else
              reward = damageDealt * CONST.REWARD_DAMAGE_DEALT_MULTIPLIER
          end

          -- For Q-Learning, we need to estimate the value of the next state.
          local nextStateActions = { ATTACK = true, SPECIAL = true, EVADE = true, FEINT = true, REPOSITION = true } -- Simplified
          local nextMaxQ = AI.Learning.GetBestNextQValue(tactic, nextStateActions)
          AI.Learning.Reinforce(tactic, action, reward, nextMaxQ)

          AI.State.comboStateEndTime = now + CONST.COMBO_WINDOW_DURATION
      end
      AI.State.lastTargetHealth = currentTargetHealth
  end

  local function ExecuteCombatLogic(now)
      if AI.State.combatState ~= "ENGAGING" or now - AI.State.lastPlanTime < CONST.PLANNING_COOLDOWN or AI.State.isFeinting then return end
      if not (AI.State.targetTorso and AI.State.targetTorso.Parent and AI.State.targetHumanoid) then return end -- Safety check

      -- Aiming and Prediction
      local ping = player:GetNetworkPing()
      local predictedPos = AI.State.targetTorso.Position + AI.State.targetTorso.AssemblyLinearVelocity * (CONST.BASE_PREDICTION_TIME + ping)
      rootPart.CFrame = CFrame.lookAt(rootPart.Position, Vector3.new(predictedPos.X, rootPart.Position.Y, predictedPos.Z))

      -- Build current state object for decision making.
      local state = {
          myHealthPercent = humanoid.Health / humanoid.MaxHealth,
          targetHealthPercent = AI.State.targetHumanoid.Health / AI.State.targetHumanoid.MaxHealth,
          distance = (rootPart.Position - AI.State.targetTorso.Position).Magnitude,
          energy = AI.State.currentEnergy,
          inRange = (rootPart.Position - AI.State.targetTorso.Position).Magnitude <= CONST.ATTACK_RANGE,
          isTargetAttacking = AI.State.isTargetAttacking,
      }

      AI.State.currentTactic = AI.Evaluation.ChooseTactic(state)
      local bestAction = AI.Evaluation.FindBestActionByScore(state, AI.State.currentTactic)
      AI.Actions.Execute(bestAction)
  end

  --// ================= EVENT CONNECTIONS ================= //
  table.insert(connections, humanoid.HealthChanged:Connect(function(newHealth)
      local damageTaken = AI.State.myHealth - newHealth
      if damageTaken > 0 then
          local penalty = damageTaken * CONST.PENALTY_DAMAGE_TAKEN_MULTIPLIER
          local failedAction = AI.State.lastAction
          if AI.State.isPerfectDodging and now > AI.State.dodgeStartTime then -- Check if dodge was active
              failedAction = "EVADE"
              AI.Learning.Reinforce(AI.State.currentTactic, "EVADE", CONST.PENALTY_FAILED_ACTION, 0)
          else
              AI.Learning.Reinforce(AI.State.currentTactic, failedAction, penalty, 0)
          end
          AI.State.isPerfectDodging = false
      elseif AI.State.isPerfectDodging and AI.State.isTargetAttacking then
          AI.Learning.Reinforce(AI.State.currentTactic, "EVADE", CONST.REWARD_PERFECT_DODGE, 0)
          AI.State.punishWindowEndTime = os.clock() + CONST.PUNISH_WINDOW_DURATION
          print("Perfect Dodge! Opening Punish Window.")
          AI.State.isPerfectDodging = false
      end
      AI.State.myHealth = newHealth
  end))

  table.insert(connections, LogService.MessageOut:Connect(function(message, messageType)
      if messageType == Enum.MessageType.MessageError and not AI.GlitchScanner.isGlitchDetected then
          local now = os.clock()
          AI.GlitchScanner.isGlitchDetected = true
          AI.GlitchScanner.glitchType = "Game Script Error"
          AI.GlitchScanner.detectionTime = now
          AI.State.glitchComboWindowEndTime = now + CONST.GLITCH_COMBO_WINDOW_DURATION
      end
  end))

  table.insert(connections, humanoid.Died:Connect(function()
      AI.Score -= 10
      print(`Project Titan defeated. New Score: {AI.Score}.`)
      Cleanup()
  end))
  table.insert(connections, character.AncestryChanged:Connect(function(_, parent)
      if not parent then Cleanup() end
  end))

  -- The main heartbeat loop that drives the AI.
  table.insert(connections, RunService.Heartbeat:Connect(function(deltaTime)
      local success, err = pcall(function()
          local now = os.clock()
          UpdateAIState(deltaTime)
          UpdateLearningAndRewards(now)
          ExecuteCombatLogic(now)
      end)
      if not success then
          warn("Project Titan encountered an error in its main loop:", err)
      end
  end))
end

--// ================= SCRIPT ENTRY POINT ================= //
-- Connect the initialization function to the CharacterAdded event.
player.CharacterAdded:Connect(initializeCombatSystem)
-- If the character already exists when the script runs, initialize immediately.
if player.Character then
  initializeCombatSystem(player.Character)
end
